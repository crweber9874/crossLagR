---
title: "The Cross Lagged Regression Model: Simulations"
header-includes:
    - \usepackage{setspace}\onehalfspacing
author: ""
date: "2025-01-21"
indent: true
output:
  pdf_document: default
---

# Introduction

The cross-lagged regression model follows an intuitive structure.  The current realizations $x$ and $y$ are a function of autoregressive and cross lagged effects. I closely follow the structure and notation in Ludtke and Robitzch (2021).

$$
\begin{bmatrix}
 y_{it}\\
 x_{it}
\end{bmatrix}
=
\begin{bmatrix}
\theta_{1y} & \theta_{1x}  \\
\theta_{2y} & \theta_{2x}  
\end{bmatrix}
\begin{bmatrix}
y_{it-1} \\ x_{it-1}  
\end{bmatrix}
+
\begin{bmatrix}
e_{y,it}\\
e_{x,it}
\end{bmatrix}
$$

$\theta_{1y}$ and $\theta_{1x}$ are the autoregressive effects and cross lagged effects in the $y$ equation. $\theta_{2y}$ and $\theta_{2x}$ represent, the cross-lagged and autoregressive effects in the $x$ equation.  The error terms $e_{y,it}$ and $e_{x,it}$ are assumed to be normally distributed with mean zero and constant variance, and uncorrelated with each other. In practice, they are often correlated, such that $cov(e^y_{t,i}, e^x_{t,i}) \neq 0$.

The random intercept specification allows for disposition, trait level effects: To what extent are $x$ and $y$ relatively unchanging and stable over time. In some cases, researchers might estimate a hierarchical model, simply allowing unique "intercepts for each unit, known as"fixed effects" terms. Variations of this model are known as the "Dynamic Random Effects Model" and "Dynamic Panel Model."  While the fixed or random effects are generally an improvement over no variation, the lagged realizations of the dependent variables in both equations complicates matters, often producing a form of bias known as "Nickell Bias" (Nickel 1981). Well-known approaches to deal with this form of bias rely on first differencing, such as the Arellano- Bond estimator, or the Bond estimator. The problem -- in a nutshell -- is that the lagged dependent variable does not include the stable, trait level variation accounted for in the random intercepts themselves (or fixed effects).

The RI-CLPM -- a popular approach in psychology -- also explicitly includes trait level variation, but in a manner somewhat different from the "dynamic panel" approaches described. For the moment, ignoring the lags and cross-lagged effects, let us assume that $x$ and $y$ are each a function of a stable trait level component, plus a time-varying state component.

$$
\begin{bmatrix}
 y_{it}\\
 x_{it}
\end{bmatrix}
=
\begin{bmatrix}
\mu^y_{i} \\
\mu^x_{i}
\end{bmatrix}
+
\begin{bmatrix}
y^*_{y,it}\\
x^*_{x,it}
\end{bmatrix}
$$

The $\mu^x_i$ and $\mu^y_i$ terms are the stable, trait level components for individual $i$. And $x^*_{t,i}$ and $y^*_{t,i}$ terms are the time-varying state components. We can view this formation as providing a decomposition of the total variance in $x$ and $y$ into between-person (trait; $\mu$) and within-person (state, $x^*,y^*$) components. From here, we can rewrite the cross-lagged and lagged effects from the state components alone.

$$
\begin{bmatrix}
 y^*_{it}\\
 x^*_{it}
\end{bmatrix}
=
\begin{bmatrix}
\theta^*_{1y} & \theta^*_{1x}  \\
\theta^*_{2y} & \theta^*_{2x}
\end{bmatrix}
\begin{bmatrix}
y^*_{it-1} \\ x^*_{it-1}
\end{bmatrix}
+
\begin{bmatrix}
e^*_{y,it}\\
e^*_{x,it}
\end{bmatrix}
$$

Taken together, the observed variables, $x$ and $y$ are a function of the intercepts, the stable, trait level components, and the lagged state components.

$$
\begin{bmatrix}
 y_{it}\\
 x_{it}
\end{bmatrix}
=
\underbrace{
\begin{bmatrix}
\theta^*_{1y} & \theta^*_{1x}  \\
\theta^*_{2y} & \theta^*_{2x}
\end{bmatrix}
\begin{bmatrix}
y^*_{it-1} \\ x^*_{t-1}
\end{bmatrix}
+
\begin{bmatrix}
e^*_{y,it}\\
e^*_{x,it}
\end{bmatrix}
}_{State}
+
\underbrace{
\begin{bmatrix}
\mu_{y,i}\\
\mu_{x,i}
\end{bmatrix}
}_{Trait}
$$

* $\mu^x_i$ and $\mu^y_i$ are the stable, trait level components for individual $i$.
* $x^*_{t,i}$ and $y^*_{t,i}$ are the time-varying state components.
* $\theta^*_{1y}$ and $\theta^*_{2x}$ are the autoregressive effects for the state components.
* $\theta^*_{1x}$ and $\theta^*_{1x}$ are the cross-lagged effects for the state components.

## Causal Effects

Extending the model, we can use the CLPM and RI-CLPM to produce potential outcomes ; what would $x_{t,i}$ and $y_{t,i}$ be if we intervened on $x$ or $y$ at time $t-1$, $E[x_{i,t}^{y_{t-1}}]$ and $E[y_{i,t}^{x_{t-1}}]$? By assuming that such an intervention is linear, similar to the structure set forth in the CLPM, the marginal effect of the treatment is $\tau$  (Ludtke and Robitzch 2021; Hernan and Robins 2020; Vanderwheele 2015). 

$$
\begin{aligned}
E[Y_{i,t}^{x_{t-1}}] = \alpha_{1} + \tau_{1} x_{t-1} \\
E[X_{i,t}^{y_{t-1}}] = \alpha_{2} + \tau_{2} y_{t-1} \\
\end{aligned}
$$

The marginal effects, $\tau$ are calculated by the expectations fixing $x_{t,i}$ and $y_{t,i}$ at a value and integrated over the joint distribution of $x_{t-1}$ and $y_{t-1}$. In a linear model, this is typically just $\hat{\theta_{1y}}$ and $\hat{\theta_{2x}}$, the slopes from a regression equation. If there are unobserved confounders, $Z$, then 

$$
\begin{aligned}
E[X_{i,t}^{y_{t-1}}]  = \tau_{1,1} = \int E[X_{i,t} | X_{i, t-1} = x_{t-1}, Y = y_{i,t-1}, \textbf{Z} =  z] f(x_{t-1}, y_{t-1}, z) dx_{t-1}dy_{t-1}d_z \\
E[Y_{i,t}^{x_{t-1}}]  = \tau_{1,2} =  \int E[Y_{i,t} | X_{i, t-1} = x_{t-1}, Y = y_{i,t-1}, \textbf{Z} = z] f(x_{t-1}, y_{t-1}, z) dx_{t-1}dy_{t-1}d_z\\
\end{aligned}
$$


The potential outcome is simply the expectation of $x_{t,i}$ and $_{y,i}$, holding $y_{t-1}$ and $x_{t-1}$ at a fixed value, and averaging over the joint distribution of $x_{t-1}$, $y_{t-1}$, and $z$.

## Confounding Variables

In the presence of confounding variables, $Z$, that influence both $x$ and $y$, the cross-lagged estimates may be biased, in both the CLPM or the RI-CLPM. A confounder, like all variables in a panel design may be *time-varying* or *time-invariant*. Some characteristics fluctuate over time, partially or fully explaining the pattern of relationships between $x$ and $y$, others are stable and tend not to change, but also explain the joint relationship between $x$ and $y$.

If confounder $z$ is time-invariant, the CLPM may be respecified as the RI-CLPM:
$$
\begin{bmatrix}
 y^*_{it}\\
 x^*_{it}
\end{bmatrix}
=
\underbrace{
\begin{bmatrix}
\theta^*_{1y} & \theta^*_{1x}  \\
\theta^*_{2y} & \theta^*_{2x}
\end{bmatrix}
\begin{bmatrix}
y^*_{it-1} \\ x^*_{t-1}
\end{bmatrix}
+
\begin{bmatrix}
e^*_{y,it}\\
e^*_{x,it}
\end{bmatrix}
}_{State}
+
\underbrace{
\begin{bmatrix}
\mu_{y,i}\\
\mu_{x,i}
\end{bmatrix}
+
\begin{bmatrix}
\alpha_{y}\\
\alpha_{x}
\end{bmatrix}
z_{i}
}_{Trait}
$$

* $\mu^x_i$ and $\mu^y_i$ are the stable, trait level components for individual $i$.
* $x^*_{t,i}$ and $y^*_{t,i}$ are the time-varying state components.
* $\theta^*_{1y}$ and $\theta^*_{2x}$ are the autoregressive effects for the state components.
* $\theta^*_{1x}$ and $\theta^*_{1x}$ are the cross-lagged effects for the state components.

When the confounder is "unobserved" and either time-invariant or time-varying, what is the consequence of ignoring that confounder in the CLPM or RI-CLPM? There is some disagreement in the literature on this question.


```{r,  warning = FALSE, message=FALSE, echo = TRUE}
library(tibble)
library(dplyr)
devtools::load_all()

## Vary these things
param_grid <- expand.grid(
  x_stability = c(0.5),
  y_stability = c(0.5),
  variance_between_x = c(0.75),
  variance_between_y = c(0.75),
  dgp = c("clpm", "clpmu", "riclpm")
)

run_monte_carlo_simulation <- function(x_stab, y_stab, var_x, var_y, dgp) {
  monteCarloCLPM(
    trials = 100,
    waves = 5,
    stability_q = y_stab,
    stability_p = x_stab,
    variance_between_y = var_y,
    variance_between_x = var_x,
    cross_p = 0.25,
    cross_q = 0.50,
    variance_p = 1,
    variance_q = 1,
    sample_size = 2500,
    dgp = dgp,
    confounder_p = 0.25,
    confounder_q = 0.25,
    confounder_variance = 1,
    confounder_stability = 0.4,
    include_confounder = include_confounder, 
    confounder_type = "time_invariant",
    cov_pq = 0.1,

  )
}
clpm_simulation_results <- param_grid |>
  rowwise() |>
  mutate(
    result = list(run_monte_carlo_simulation(
      x_stab = x_stability,
      y_stab = y_stability, 
      var_x = variance_between_x,
      var_y = variance_between_y,
      dgp = dgp
    ))
  ) |>
  ungroup() |>
  tidyr::unnest()
```

## Setup 

* `_stability` are  the autoregressive parameters -- in the x-equation and y-equation. I simulate the effect of varying stability in both equations at 0.5

* `variance_between_` are the variance parameters when simulating data under a RICLPM. They are fixed at 0.75

* We fix the cross-lagged effect of $x$ on $y$ at 0.25

* We fix the cross-lagged effect of *y* on *x* at 0.50

* The variances of the wave specific latent variable are fixed at 1.

* When a confounder is specified, it is *time-invariant* and with a slope of 0.25 when predicting the latent factors.

* The confounder variance, when this DGP is used is fixed to 1.

* The simulations were run for 100 trials in each DGP condition.


Three DGPs are used.

* The `clpm`

* The `clpm` with a time invariant confounder

 The `riclpm` which varies the stable, trait level variation in both x and y.


To simplify the presentation, I estimated the degree of bias in the cross-lagged parameter -- the parameter of interest -- which is simply $\hat{\theta}$ - $\theta$. I also show the relative bias, which is simply the bias divided by the true value, then multipled by 100. I then averaged across every simulation condition below

## The Results

The only thing varying in the simulations is the DGP: (1) random-intercept cross lagged, (2) cross lagged with time invariant confounder, (3) cross lagged without confounder; the stability in the x and y equations; the amount of stable, trait level variation in x and y (when the riclpm dgp is used). 


```{r, warning = FALSE, message=FALSE, echo= FALSE}
library(tidyr)
library(dplyr)
library(gt)

param_grid <- expand.grid(
  x_stability = c(0.5),
  y_stability = c(0.5),
  variance_between_x = c(0.75),
  variance_between_y = c(0.75),
  include_confounder    = c(FALSE),
  dgp = c("clpm", "clpmu", "riclpm")
)

bias_analysis <- function(
    simulation_results,
    param_grid,
    dgp_filter = c("clpm", "clpmu", "riclpm"),
    x_stability_filter = c(0.5),
    y_stability_filter = c(0.5),
    variance_between_x_filter = c(0.75),
    variance_between_y_filter = c(0.75),
    include_confounder_filter = c(FALSE, TRUE)
) {

  # Perform bias calculations and summarization
  bias_analysis_summary <- clpm_simulation_results %>%
    mutate(
      cross_p_bias = ylag_x - 0.5,
      cross_q_bias = xlag_y - 0.25,
      relative_cross_p_bias = (cross_p_bias / 0.5) * 100,
      relative_cross_q_bias = (cross_q_bias / 0.25) * 100
    ) |>
    group_by(across(all_of(names(param_grid)))) |>
    summarize(
      mean_cross_p_bias = mean(cross_p_bias, na.rm = TRUE),
      mean_cross_q_bias = mean(cross_q_bias, na.rm = TRUE),
      mean_relative_cross_p_bias = mean(relative_cross_p_bias, na.rm = TRUE),
      mean_relative_cross_q_bias = mean(relative_cross_q_bias, na.rm = TRUE),
      .groups = "drop"
    )

  # Filter results based on function arguments
  filtered_results <- bias_analysis_summary |>
    filter(
      dgp %in% dgp_filter,
      x_stability %in% x_stability_filter,
      y_stability %in% y_stability_filter,
      variance_between_x %in% variance_between_x_filter,
      variance_between_y %in% variance_between_y_filter,
    )
  
  return(filtered_results)
}

bias_analysis(
  simulation_results = clpm_simulation_results,
  param_grid = param_grid,
  dgp_filter = c("clpm", "clpmu", "riclpm"),
  x_stability_filter = c(0.5),
  y_stability_filter = c(0.5),
  variance_between_x_filter = c(0.75),
  variance_between_y_filter = c(0.75),
  # include_confounder_filter = c(TRUE, FALSE)
) |>
  select(dgp, mean_cross_p_bias, mean_cross_q_bias,
         mean_relative_cross_p_bias, mean_relative_cross_q_bias) |>
   pivot_longer(cols = -dgp, names_to = "parameter", values_to = "bias") |>
   pivot_wider(names_from = dgp, values_from = bias) |>
  mutate(
    parameter = case_when(
      parameter == "mean_cross_p_bias" ~ "Bias in Cross Lagged X~Y",
      parameter == "mean_cross_q_bias" ~ "Bias in Cross Lagged Y~X",
      parameter == "mean_relative_cross_p_bias" ~ "Relative Bias in Cross Lagged Y~X",
      parameter == "mean_relative_cross_q_bias" ~ "Relative Bias in Cross Lagged X~Y")
    )|>
  gt() |>
  tab_header(
    title = md("**Monte Carlo Bias Analysis**"),
    subtitle = "CLPM Simulation: Varying the DGP"
  ) |>
  cols_label(
    parameter = "Parameter",
    clpmu =  "CLPM, Confounder",
    clpm  =  "CLPM, No Confounder",
    riclpm = "RICLPM",
) |>
    fmt_number(
    columns = c(clpm, clpmu, riclpm),  # All numeric columns
    decimals = 3  # Change this number to control decimals
  ) |>
  tab_source_note(
    source_note = md("*Note*: The results reported here are from 100 simulations.")
   ) |>
   tab_footnote(
     footnote = "Bias = Mean(estimate) - True value, Relative Bias = (Bias / True value) * 100",
     locations = cells_column_labels(columns = starts_with("Y_"))
   )
# 
# 

```



## Estimation with the RI-CLPM

The same, but using the RI-CLPM to estimate the models from the three DGPs.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tibble)
library(dplyr)
devtools::load_all()

## Vary these things
param_grid <- expand.grid(
  x_stability = c(0.20),
  y_stability = c(0.20),
  variance_between_x = c(0.70),
  variance_between_y = c(0.70),
  dgp = c("clpm", "clpmu", "riclpm")
)

run_monte_carlo_simulation_riclpm <- function(x_stab, y_stab, var_x, var_y, dgp) {
  monteCarloRICLPM(
    trials = 100,
    waves = 5,
    stability_q = y_stab,
    stability_p = x_stab,
    variance_between_y = var_y,
    variance_between_x = var_x,
    cross_p = 0.25,
    cross_q = 0.50,
    variance_p = 1,
    variance_q = 1,
    sample_size = 2500,
    dgp = dgp,
    confounder_p = 0.25,
    confounder_q = 0.25,
    confounder_variance = 1,
    confounder_stability = 0.4,
    confounder_type = "time_invariant",
    cov_pq = 0.1,

  )
}
riclpm_simulation_results <- param_grid |>
  rowwise() |>
  mutate(
    result = list(run_monte_carlo_simulation_riclpm(
      x_stab = x_stability,
      y_stab = y_stability, 
      var_x = variance_between_x,
      var_y = variance_between_y,
      dgp = dgp
    ))
  ) |>
  ungroup() |>
  tidyr::unnest()
```





```{r, echo = FALSE, warning = FALSE, message = FALSE}
#### Plot some results ###
library(tidyr)
library(dplyr)
library(gt)

param_grid <- expand.grid(
  x_stability = c(0.20),
  y_stability = c(0.20),
  variance_between_x = c(0.70),
  variance_between_y = c(0.70),
  dgp = c("clpm", "clpmu", "riclpm")
)

bias_analysis <- function(
    simulation_results,
    param_grid,
    dgp_filter = c("clpm", "clpmu", "riclpm"),
    x_stability_filter = c(0.5),
    y_stability_filter = c(0.5),
    variance_between_x_filter = c(0.75),
    variance_between_y_filter = c(0.75),
    include_confounder_filter = c(FALSE, TRUE)
) {

  # Perform bias calculations and summarization
  bias_analysis_summary <- riclpm_simulation_results %>%
    mutate(
      cross_p_bias = ylag_x - 0.5,
      cross_q_bias = xlag_y - 0.25,
      relative_cross_p_bias = (cross_p_bias / 0.5) * 100,
      relative_cross_q_bias = (cross_q_bias / 0.25) * 100
    ) |>
    group_by(across(all_of(names(param_grid)))) |>
    summarize(
      mean_cross_p_bias = mean(cross_p_bias, na.rm = TRUE),
      mean_cross_q_bias = mean(cross_q_bias, na.rm = TRUE),
      mean_relative_cross_p_bias = mean(relative_cross_p_bias, na.rm = TRUE),
      mean_relative_cross_q_bias = mean(relative_cross_q_bias, na.rm = TRUE),
      .groups = "drop"
    )

  # Filter results based on function arguments
  filtered_results <- bias_analysis_summary |>
    filter(
      dgp %in% dgp_filter,
      x_stability %in% x_stability_filter,
      y_stability %in% y_stability_filter,
      variance_between_x %in% variance_between_x_filter,
      variance_between_y %in% variance_between_y_filter,
    )
  
  return(filtered_results)
}

bias_analysis(
  simulation_results = riclpm_simulation_results,
  param_grid = param_grid,
  dgp_filter = c("clpm", "clpmu", "riclpm"),
  x_stability_filter = c(0.2),
  y_stability_filter = c(0.2),
  variance_between_x_filter = c(0.7),
  variance_between_y_filter = c(0.7),
  # include_confounder_filter = c(TRUE, FALSE)
) |>
  select(dgp, mean_cross_p_bias, mean_cross_q_bias,
         mean_relative_cross_p_bias, mean_relative_cross_q_bias) |>
   pivot_longer(cols = -dgp, names_to = "parameter", values_to = "bias") |>
   pivot_wider(names_from = dgp, values_from = bias) |>
  mutate(
    parameter = case_when(
      parameter == "mean_cross_p_bias" ~ "Bias in Cross Lagged X~Y",
      parameter == "mean_cross_q_bias" ~ "Bias in Cross Lagged Y~X",
      parameter == "mean_relative_cross_p_bias" ~ "Relative Bias in Cross Lagged Y~X",
      parameter == "mean_relative_cross_q_bias" ~ "Relative Bias in Cross Lagged X~Y")
    )|>
  gt() |>
  tab_header(
    title = md("**Monte Carlo Bias Analysis**"),
    subtitle = "RICLPM Simulation: Varying the DGP"
  ) |>
  cols_label(
    parameter = "Parameter",
    clpmu =  "CLPM, Confounder",
    clpm  =  "CLPM, No Confounder",
    riclpm = "RICLPM",
) |>
    fmt_number(
    columns = c(clpm, clpmu, riclpm),  # All numeric columns
    decimals = 3  # Change this number to control decimals
  ) |>
  tab_source_note(
    source_note = md("*Note*: The results reported here are from 100 simulations.")
   ) |>
   tab_footnote(
     footnote = "Bias = Mean(estimate) - True value,
     Relative Bias = (Bias / True value) * 100",
     locations = cells_column_labels(columns = starts_with("Y_"))
   )
# 
# 

```


### Limitations of the RI-CLPM

One of the issues that frequently emerges when estimating an RI-CLPM in practice, is that the model fails to converge, or produces inadmissible solutions. This is particularly true when the amount of stable, trait level variation is high, accounting for much of the variation in the x and y variables. On the other hand, there is very little remaining "state" variation.

To illustrate this point, I run a series of simulations where I vary the amount of stable, trait level variation in both x and y from 0 to 0.3 (in increments of 0.05) while holding other parameters constant. The "between-subject" (or random intercept) variance is quite high, set at 1. 


```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tibble)
library(dplyr)
devtools::load_all()

## Vary these things
param_grid <- expand.grid(
  x_stability = c(0.05),
  y_stability = c(0.05),
  variance_between_x = c(1),
  variance_between_y = c(1),
  variance_p = seq(0.0, 0.15,  by =  0.05),
  variance_q = seq(0.0, 0.15,  by  = 0.05),
  dgp = c("riclpm")
)

run_monte_carlo_simulation_riclpm <- function(x_stab, y_stab, var_x, var_y, dgp,
                                              variance_p, variance_q) {
  monteCarloRICLPM(
    trials = 100,
    waves = 5,
    stability_q = y_stab,
    stability_p = x_stab,
    variance_between_y = var_y,
    variance_between_x = var_x,
    cross_p = 0.10,
    cross_q = 0.15,
    variance_p = variance_p,
    variance_q = variance_q,
    sample_size = 2500,
    dgp = dgp,
    confounder_p = 0.25,
    confounder_q = 0.25,
    confounder_variance = 1,
    confounder_stability = 0.4,
    confounder_type = "time_invariant",
    cov_pq = 0.1,

  )
}
riclpm_simulation_results <- param_grid |>
  rowwise() |>
  mutate(
    result = list(run_monte_carlo_simulation_riclpm(
      x_stab = x_stability,
      y_stab = y_stability, 
      var_x = variance_between_x,
      var_y = variance_between_y,
      variance_p = variance_p,
      variance_q = variance_q,
      dgp = dgp
    ))
  ) |>
  ungroup() |>
  tidyr::unnest()
```

The model has a high failure rate when the amount of stable, trait level variation is high, and the amount of state variation is quite low. 


```{r, echo = FALSE, warning = FALSE, message = FALSE}
riclpm_simulation_results %>%
    group_by(variance_p, variance_q) %>%
    summarise(
        failure_rate = mean(converged == FALSE) * 100,
        .groups = 'drop'
    )  |> 
  rename(Within_Subject_Y = variance_p, Within_Subject_X = variance_q) |>
  
  print()
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(gt)
riclpm_simulation_results %>%
    group_by(variance_p, variance_q) %>%
    summarise(
        check_covariance= mean(error_message == "lavaan->lav_start_check_cov():  \n   please provide better fixed values for (co)variances; variables involved are: p1 q1") * 100,
        sigma_not_positive_definite = mean(error_message ==  "'Sigma' is not positive definite") * 100,
        sample_matrix_not_positive_definite = mean(error_message ==  "lavaan->lav_samplestats_icov():  \n   sample covariance matrix is not positive-definite") * 100,
        model_did_not_converge = mean(error_message ==  "Model did not converge") * 100,
        .groups = 'drop'
    )  |>
tidyr::replace_na(list(
    check_covariance = 0,
    sigma_not_positive_definite = 0,
    sample_matrix_not_positive_definite = 0,
    model_did_not_converge = 0
  )) |>
  print()
```
